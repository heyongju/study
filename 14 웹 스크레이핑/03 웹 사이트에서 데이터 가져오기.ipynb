{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = 'https://www.alexa.com/topsites/countries/KR'\n",
    "\n",
    "html_website_ranking = requests.get(url).text\n",
    "soup_website_ranking = BeautifulSoup(html_website_ranking, 'lxml')\n",
    "\n",
    "# p íƒœê·¸ì˜ ìš”ì†Œ ì•ˆì—ì„œ a íƒœê·¸ì˜ ìš”ì†Œë¥¼ ì°¾ìŒ\n",
    "website_ranking = soup_website_ranking.select('p a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Google.com'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "website_ranking[1].get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "website_ranking_adress = [website_ranking_element.get_text() for website_ranking_element in \n",
    "                         website_ranking]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Google.com',\n",
       " 'Naver.com',\n",
       " 'Youtube.com',\n",
       " 'Daum.net',\n",
       " 'Tistory.com',\n",
       " 'Tmall.com']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "website_ranking_adress[1:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "íƒ‘ë®¤ì§\n",
      "1: Dynamite\n",
      "2: Lovesick Girls\n",
      "3: DON'T TOUCH ME\n",
      "4: ì ì´ ì˜¤ì§ˆ ì•Šë„¤ìš”\n",
      "5: ì·¨ê¸°ë¥¼ ë¹Œë ¤ (ì·¨í–¥ì €ê²© ê·¸ë…€ X ì‚°ë“¤)\n",
      "6: í˜ë“  ê±´ ì‚¬ë‘ì´ ì•„ë‹ˆë‹¤\n",
      "7: I CAN'T STOP ME\n",
      "8: Savage Love (Laxed - Siren Beat) (BTS Remix)\n",
      "9: ë”©ê°€ë”©ê°€ (Dingga)\n",
      "10: ë§ˆë¦¬ì•„ (Maria)\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = 'https://music.naver.com/listen/top100.nhn?domain=TOTAL_V2'\n",
    "\n",
    "html = requests.get(url).text\n",
    "soup = BeautifulSoup(html, 'lxml')\n",
    "rank = soup.select('a._title')\n",
    "adress = [ranking.get_text() for ranking in rank]\n",
    "\n",
    "print(\"íƒ‘ë®¤ì§\")\n",
    "for k in range(10):\n",
    "    print(f'{k+1}: {adress[k]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ê¸´ë°•ì—”ë”©] ì´ì§€ì•„, ê¹€ì†Œì—°Ã—ì—„ê¸°ì¤€ ë¶ˆë¥œ í˜„ì¥ ëª©ê²© í›„ ë“¤í‚¤ê¸° â€˜ì¼ë³´ ì§ì „!â€™\n",
      "ì ì‹œë§Œ ì•ˆë…•. ê¹€í˜¸ì¤‘ êµ°ë³µë¬´ì „ ë§ˆì§€ë§‰ ë¬´ëŒ€ ï¼œë°°ì›…ï¼ã…£ê¹€í˜¸ì¤‘ì˜íŒŒíŠ¸ë„ˆ EP.5\n",
      "ì„ì‹  í™•ë¥  ê²¨ìš° 4%ğŸ˜­ ë‘˜ì§¸ ì›í•˜ëŠ” ì´ìœ !?\n",
      "ì„ì˜ì›… â€˜ì˜›ì‚¬ë‘â€™ â™ª ê°ì„± ì¥ì¸ íˆì–´ë¡œ ğŸ’§\n",
      "[í‚¤ìŠ¤ ì—”ë”©] ï¼‚ë³´ê³  ì‹¶ì—ˆì–´...ï¼‚ ê¹€í•˜ëŠ˜â™¥ì´ë„í˜„ì˜ ë³€í•˜ì§€ ì•Šì€ ì‚¬ë‘\n",
      "[ì„ ê³µê°œ] ì£¼ì €ì•‰ì€ ê¹€ë²”! ì´ë™ìš±ê³¼ ì•„ê·€ì˜ ìˆ² íƒˆì¶œ í¬ê¸°?\n",
      "ì´ì§€ì•„, ì´ì² ë¯¼ì´ ë§í•œ ì¹œë”¸ ê´€ë ¨ëœ ì§„ì‹¤ì— â€˜ì˜¤ì—´â€™ (ft. ì—„ê¸°ì¤€ ì†Œë¦„)\n",
      "17ì‚´ ì°¨ì´ë‚˜ëŠ” ë°•íœ˜ìˆœâ™¥ì²œì˜ˆì§€ ë¶€ë¶€!! ë‚˜ì´ë³´ë‹¨ ì‚¬ë‘ì´ ìš°ì„ ì´ë‹¤..â˜†\n",
      "ì´ì§€ì•„, ì§„ì§œ ì¹œë”¸ ì•ˆ ë’¤ ì¡°ìˆ˜ë¯¼ì´ ë‹¹í•œ ê³¼ê±° íšŒìƒì— â€˜ëˆˆë¬¼â€™\n",
      "â€œí›„ì‹ì€ ì¤‘êµ­ì§‘â€ ê¹€í˜¸ì¤‘Ã—í˜„ì£¼ì—½, ëë‚˜ì§€ ì•ŠëŠ” ë¨¹ë ˆì´ìŠ¤!\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = 'https://tv.naver.com/r/'\n",
    "\n",
    "html = requests.get(url).text\n",
    "soup = BeautifulSoup(html,'lxml')\n",
    "titles = soup.select('dt.title')\n",
    "rank = [title.get_text() for title in titles]\n",
    "for i in rank[0:10]:\n",
    "    print(i.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì—°ë„ë¥¼ ì…ë ¥í•˜ì„¸ìš” 2020\n",
      "ì›”ì„ ì…ë ¥í•˜ì„¸ìš” 3\n",
      "ì£¼ë¥¼ ì…ë ¥í•˜ì„¸ìš” 2\n",
      "METEOR\n",
      "Psycho\n",
      "Blueming\n",
      "HIP\n",
      "Square (2017)\n",
      "ì–´ë–»ê²Œ ì´ë³„ê¹Œì§€ ì‚¬ë‘í•˜ê² ì–´, ë„ ì‚¬ë‘í•˜ëŠ” ê±°ì§€\n",
      "Love poem\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "year = input('ì—°ë„ë¥¼ ì…ë ¥í•˜ì„¸ìš” ')\n",
    "month = input('ì›”ì„ ì…ë ¥í•˜ì„¸ìš” ')\n",
    "week = input('ì£¼ë¥¼ ì…ë ¥í•˜ì„¸ìš” ')\n",
    "\n",
    "if len(month) == 1: month = '0'+month\n",
    "\n",
    "url = f\"http://music.naver.com/listen/history/index.nhn?type=TOTAL&year={year}&month={month}&week={week}\"\n",
    "html_music = requests.get(url).text\n",
    "soup_music = BeautifulSoup(html_music, \"lxml\")\n",
    "\n",
    "# a íƒœê·¸ì˜ ìš”ì†Œ ì¤‘ì—ì„œ class ì†ì„±ê°’ì´ \"_title\" ì¸ ê²ƒì„ ì°¾ê³ \n",
    "# ê·¸ ì•ˆì—ì„œ span íƒœê·¸ì˜ ìš”ì†Œ ì¤‘ì—ì„œ class ì†ì„±ê°’ì´ \"ellipsis\"ì¸ ìš”ì†Œë¥¼ ì¶”ì¶œ\n",
    "titles = soup_music.select('a._title span.ellipsis') \n",
    "\n",
    "\n",
    "for title in titles[0:7]:\n",
    "    print(title.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\r\\n\\t\\t\\t\\r\\n\\t\\t\\t\\r\\n\\t\\t\\tì°½ëª¨(CHANGMO)\\r\\n\\t\\t\\n'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a íƒœê·¸ì˜ ìš”ì†Œ ì¤‘ì—ì„œ class ì†ì„±ê°’ì´ \"_artist\" ì¸ ê²ƒì„ ì°¾ê³ \n",
    "# ê·¸ ì•ˆì—ì„œ span íƒœê·¸ì˜ ìš”ì†Œ ì¤‘ì—ì„œ class ì†ì„±ê°’ì´ \"ellipsis\"ì¸ ìš”ì†Œë¥¼ ì¶”ì¶œ\n",
    "\n",
    "artists = soup_music.select('td._artist a')\n",
    "artists[0].get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì°½ëª¨(CHANGMO)\n",
      "Red Velvet (ë ˆë“œë²¨ë²³)\n",
      "ì•„ì´ìœ (IU)\n",
      "ë§ˆë§ˆë¬´(Mamamoo)\n",
      "ë°±ì˜ˆë¦°\n",
      "AKMU (ì•…ë™ë®¤ì§€ì…˜)\n",
      "ì•„ì´ìœ (IU)\n"
     ]
    }
   ],
   "source": [
    "music_artists = [artist.get_text().strip() for artist in artists]\n",
    "music_artists[0:7]\n",
    "for music_artist in music_artists[0:7]:\n",
    "    print(music_artist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì—°ë„ë¥¼ ì…ë ¥í•˜ì„¸ìš” 2020\n",
      "ì›”ì„ ì…ë ¥í•˜ì„¸ìš” 3\n",
      "ì£¼ë¥¼ ì…ë ¥í•˜ì„¸ìš” 1\n",
      "1.METEOR - ì°½ëª¨(CHANGMO)\n",
      "2.Psycho - Red Velvet (ë ˆë“œë²¨ë²³)\n",
      "3.Blueming - ì•„ì´ìœ (IU)\n",
      "4.HIP - ë§ˆë§ˆë¬´(Mamamoo)\n",
      "5.Square (2017) - ë°±ì˜ˆë¦°\n",
      "6.ì–´ë–»ê²Œ ì´ë³„ê¹Œì§€ ì‚¬ë‘í•˜ê² ì–´, ë„ ì‚¬ë‘í•˜ëŠ” ê±°ì§€ - AKMU (ì•…ë™ë®¤ì§€ì…˜)\n",
      "7.Love poem - ì•„ì´ìœ (IU)\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "year = input('ì—°ë„ë¥¼ ì…ë ¥í•˜ì„¸ìš” ')\n",
    "month = input('ì›”ì„ ì…ë ¥í•˜ì„¸ìš” ')\n",
    "week = input('ì£¼ë¥¼ ì…ë ¥í•˜ì„¸ìš” ')\n",
    "\n",
    "if len(month) == 1: month = '0'+month\n",
    "\n",
    "url = f\"http://music.naver.com/listen/history/index.nhn?type=TOTAL&year={year}&month={month}&week={week}\"\n",
    "html_music = requests.get(url).text\n",
    "soup_music = BeautifulSoup(html_music, \"lxml\")\n",
    "\n",
    "# a íƒœê·¸ì˜ ìš”ì†Œ ì¤‘ì—ì„œ class ì†ì„±ê°’ì´ \"_title\" ì¸ ê²ƒì„ ì°¾ê³ \n",
    "# ê·¸ ì•ˆì—ì„œ span íƒœê·¸ì˜ ìš”ì†Œ ì¤‘ì—ì„œ class ì†ì„±ê°’ì´ \"ellipsis\"ì¸ ìš”ì†Œë¥¼ ì¶”ì¶œ\n",
    "titles = soup_music.select('a._title span.ellipsis') \n",
    "\n",
    "# a íƒœê·¸ì˜ ìš”ì†Œ ì¤‘ì—ì„œ class ì†ì„±ê°’ì´ \"_artist\" ì¸ ê²ƒì„ ì°¾ê³ \n",
    "# ê·¸ ì•ˆì—ì„œ span íƒœê·¸ì˜ ìš”ì†Œ ì¤‘ì—ì„œ class ì†ì„±ê°’ì´ \"ellipsis\"ì¸ ìš”ì†Œë¥¼ ì¶”ì¶œ\n",
    "\n",
    "artists = soup_music.select('td._artist a')\n",
    "\n",
    "for k in range(7):\n",
    "    print(f'{k+1}.{titles[k].get_text().strip()} - {artists[k].get_text().strip()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:/myPyCode/data/NaverMusicTop100.xlsx']"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import glob\n",
    "\n",
    "naver_music_url = \"http://music.naver.com/listen/history/index.nhn?type=DOMESTIC&year=2017&month=12&week=1&page=\"\n",
    " \n",
    "# ë„¤ì´ë²„ music ì£¼ì†Œë¥¼ ì…ë ¥í•˜ë©´ ë…¸ë˜ ì œëª©ê³¼ ì•„í‹°ìŠ¤íŠ¸ë¥¼ ë°˜í™˜\n",
    "def naver_music(url):    \n",
    "    html_music = requests.get(url).text\n",
    "    soup_music = BeautifulSoup(html_music, \"lxml\")\n",
    "\n",
    "    titles = soup_music.select('a._title span.ellipsis') \n",
    "    artists = soup_music.select('td._artist a')\n",
    "\n",
    "    music_titles = [title.get_text() for title in titles]\n",
    "    music_artists = [artist.get_text().strip() for artist in artists]\n",
    "    \n",
    "    return music_titles, music_artists\n",
    "\n",
    "# ë…¸ë˜ ì œëª©ê³¼ ì•„í‹°ìŠ¤íŠ¸ë¥¼ ì €ì¥í•  íŒŒì¼ ì´ë¦„ì„ í´ë”ì™€ í•¨ê»˜ ì§€ì •\n",
    "file_name = 'C:/myPyCode/data/NaverMusicTop100.txt'\n",
    "\n",
    "f = open(file_name,'w') # íŒŒì¼ ì—´ê¸°\n",
    "\n",
    "# ê° pageì—ëŠ” 50ê°œì˜ ë…¸ë˜ ì œëª©ê³¼ ì•„í‹°ìŠ¤íŠ¸ê°€ ì¶”ì¶œë¨\n",
    "for page in range(2):\n",
    "    naver_music_url_page = naver_music_url + str(page+1) # page URL\n",
    "    naver_music_titles, naver_music_artists = naver_music(naver_music_url_page)\n",
    "    \n",
    "    # ì¶”ì¶œëœ ë…¸ë˜ ì œëª©ê³¼ ì•„í‹°ìŠ¤íŠ¸ë¥¼ íŒŒì¼ì— ì €ì¥ \n",
    "    for k in range(len(naver_music_titles)):\n",
    "        f.write(\"{0:2d}: {1}/{2}\\n\".format(page*50 + k+1, naver_music_titles[k],  naver_music_artists[k]))\n",
    "        \n",
    "f.close() # íŒŒì¼ ë‹«ê¸°\n",
    "glob.glob(file_name) # ìƒì„±ëœ íŒŒì¼ í™•ì¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['HERO', 'ì„ì˜ì›…']\n",
      "['í˜¸ë‘ì´ëŠ” ì£½ì–´ì„œ ê°€ì£½ì„, ìš°ë¦¬ëŠ” ì´ë¦„ì„', 'í™ˆë³´ì´ (Homeboy), ì—ë„¤ì´ ì—ë¯¸ (Enei Emi)']\n",
      "['ë–¨ì–´ì ¸ (Please Go Away)', 'NIDA']\n",
      "['ì‹¸ì´ì½”4U', 'ê±¸ì¹´ì¸ë“œ (GIRLKIND)']\n",
      "['AYA', 'ë§ˆë§ˆë¬´ (Mamamoo)']\n",
      "['SOON (Feat. BewhY)', 'ë‹¤ì´ë‚˜ë¯¹ ë“€ì˜¤']\n",
      "['Bangkok (Stay Home)', 'ë·°í‹°í•¸ì„¬']\n",
      "['By your side (Feat. E.N.D., SLOC)', 'TSLW']\n",
      "['ì–´ì©Œë©´ ì˜¤ë˜ì „ë¶€í„°', 'ìº¡í‹´í”Œë˜ë‹›, ì´ì€ì•„']\n",
      "['Winter again', 'Yolk']\n",
      "['ì–˜ë‘ ìˆì„ ë•Œ ì¢‹ë‹¤(with ê¹€êµ­í—Œ of ë¹„ì˜¤ë¸Œìœ )', 'ì–´ì¿ ìŠ¤í‹± ì½œë¼ë³´']\n",
      "[\"I'm alone\", 'The Hills (ë” íìŠ¤)']\n",
      "['Wind, Star (feat. ì´ìƒí›ˆ of í›ˆìŠ¤ (HOONS))', 'ë¦´ë¦¬ë…¸íŠ¸ (Lilynote)']\n",
      "['ë°±ì¼í™', 'ì¡°ëª…ì„­']\n",
      "['ì”ìƒ (Vocal. ì •êµ¬ì˜)', 'ê¹€í˜„ìˆ˜ (F-IV)']\n",
      "['ê·€ê°€ (With íƒ€ë¯¸ì¦ˆ)', '42kgb']\n",
      "['ë„ˆë¼ëŠ” í•˜ë£¨ë¥¼ ì‚´ì•„', 'ì£¼í˜¸']\n",
      "['ê·¸ë•Œ ìƒê°ë‚˜?(Remember that time?)', 'ë² ì´ë¹„ë¸”ë£¨(BABY BLUE)']\n",
      "['i got you', 'Jimmy Brown']\n",
      "['On The Radio (With SERO)', 'SUDI']\n",
      "['ì„œìš¸', 'ì„ì˜ˆì†¡']\n",
      "['Love Killa', 'ëª¬ìŠ¤íƒ€ì—‘ìŠ¤']\n",
      "['SALUTE', 'AB6IX (ì—ì´ë¹„ì‹ìŠ¤)']\n",
      "['ë¹„í–‰ê¸° ëª¨ë“œ (Feat. ë°”ë¼ë¦¬, BRADYSTREET)', 'ë‚˜ì™”êµ¬ë‚˜ ê¹€ë¹„ë…¸']\n",
      "['ì•ˆë¼ìš”', 'í™ì§„ì˜']\n",
      "['G.B.T.B. (Strong Dragon Remix)', 'VERIVERY']\n",
      "['OFF', 'ìƒˆë²½ë‘ì‹œ']\n",
      "['I need you. Period.', 'Kim Jeong_uk(ê¹€ì •ìš±)']\n",
      "['ì¢‹ì•„ ì¢‹ì•„', 'ì •ë‹¤ê²½']\n",
      "['ê°•ì„ í–¥í•´ ê°„ë‹¤', 'ìŠ¤ë§ˆì¼ë¦¬ìŠ¤ë§ˆì¼ (SmileySmile)']\n",
      "['INTRCRSE (Feat. ë°”ë¼ë¦¬)', 'DOPA']\n",
      "['Fxxkin Insomnia', 'MÃ–A']\n",
      "['ì†Œë…„', 'ì‹ ì§€ë¯¼']\n",
      "['MOVIE (Feat. Rohann)', 'ì •ì§„ìš°']\n",
      "['í…… ë¹„ì—ˆë˜(ft. ì„œí•œ)', 'Xbf']\n",
      "[\"DIVIN' (Feat. z4vwm (ì¡ìŒ), JUICY KID)\", 'ì˜¨ë¦¬ì°¨ì¼ë“œ (ONLICHILD)']\n",
      "['ê·¸ëŒ€ ê·¸ë¦¬ìš´ ë‚ ', 'ì„¤ê°€ë ¹']\n",
      "['Love you Love you (feat.ë” ë¸Œë¦¿ì§€(The Bridge))', 'ë¸ŒëŸ°ì¹˜ ë ˆì‹œí”¼ (Brunch recipe)']\n",
      "['Labyrinth', 'ì •ì£¼ (Jungju)']\n",
      "['Be bop a lula', 'ì–¼ìŠ¤ (Earls), ì´ì² í˜¸']\n",
      "['Lazy Seoul (ë ˆì´ì§€ ì„œìš¸)', 'ì œì´ì¼ ']\n",
      "['ì˜¨ë„ì°¨', 'í™”ì (HWAJA)']\n",
      "['ë‚´ë²„ë ¤ë‘¬(NOYB)', 'BXK']\n",
      "['íƒœì–‘', 'ì´ì¤€í˜•']\n",
      "['Overdose (feat. Tommy Strate)', 'Claire Hau (í´ë ˆì–´ í•˜ìš°)']\n",
      "['My Love', 'ë‹¤ë¹„ì¹˜']\n",
      "['ìš°ë¦¬ ë©€ë¦¬ ë– ë‚ ê¹Œ (feat. ì •ê¸°ê³ )', 'ê³ ë‹¥']\n",
      "['minimal warm (ì·¨í–¥ì €ê²© ê·¸ë…€ X ì°¬ì—´ (CHANYEOL))', 'ì°¬ì—´ (CHANYEOL)']\n",
      "['My Universe (Prod. by Minit)', 'Holynn']\n",
      "['Traveler (feat. Zooy, Vibin)', 'TAETAE']\n",
      "['HERO', 'ì„ì˜ì›…']\n",
      "['í˜¸ë‘ì´ëŠ” ì£½ì–´ì„œ ê°€ì£½ì„, ìš°ë¦¬ëŠ” ì´ë¦„ì„', 'í™ˆë³´ì´ (Homeboy), ì—ë„¤ì´ ì—ë¯¸ (Enei Emi)']\n",
      "['ë–¨ì–´ì ¸ (Please Go Away)', 'NIDA']\n",
      "['ì‹¸ì´ì½”4U', 'ê±¸ì¹´ì¸ë“œ (GIRLKIND)']\n",
      "['AYA', 'ë§ˆë§ˆë¬´ (Mamamoo)']\n",
      "['SOON (Feat. BewhY)', 'ë‹¤ì´ë‚˜ë¯¹ ë“€ì˜¤']\n",
      "['Bangkok (Stay Home)', 'ë·°í‹°í•¸ì„¬']\n",
      "['By your side (Feat. E.N.D., SLOC)', 'TSLW']\n",
      "['ì–´ì©Œë©´ ì˜¤ë˜ì „ë¶€í„°', 'ìº¡í‹´í”Œë˜ë‹›, ì´ì€ì•„']\n",
      "['Winter again', 'Yolk']\n",
      "['ì–˜ë‘ ìˆì„ ë•Œ ì¢‹ë‹¤(with ê¹€êµ­í—Œ of ë¹„ì˜¤ë¸Œìœ )', 'ì–´ì¿ ìŠ¤í‹± ì½œë¼ë³´']\n",
      "[\"I'm alone\", 'The Hills (ë” íìŠ¤)']\n",
      "['Wind, Star (feat. ì´ìƒí›ˆ of í›ˆìŠ¤ (HOONS))', 'ë¦´ë¦¬ë…¸íŠ¸ (Lilynote)']\n",
      "['ë°±ì¼í™', 'ì¡°ëª…ì„­']\n",
      "['ì”ìƒ (Vocal. ì •êµ¬ì˜)', 'ê¹€í˜„ìˆ˜ (F-IV)']\n",
      "['ê·€ê°€ (With íƒ€ë¯¸ì¦ˆ)', '42kgb']\n",
      "['ë„ˆë¼ëŠ” í•˜ë£¨ë¥¼ ì‚´ì•„', 'ì£¼í˜¸']\n",
      "['ê·¸ë•Œ ìƒê°ë‚˜?(Remember that time?)', 'ë² ì´ë¹„ë¸”ë£¨(BABY BLUE)']\n",
      "['i got you', 'Jimmy Brown']\n",
      "['On The Radio (With SERO)', 'SUDI']\n",
      "['ì„œìš¸', 'ì„ì˜ˆì†¡']\n",
      "['Love Killa', 'ëª¬ìŠ¤íƒ€ì—‘ìŠ¤']\n",
      "['SALUTE', 'AB6IX (ì—ì´ë¹„ì‹ìŠ¤)']\n",
      "['ë¹„í–‰ê¸° ëª¨ë“œ (Feat. ë°”ë¼ë¦¬, BRADYSTREET)', 'ë‚˜ì™”êµ¬ë‚˜ ê¹€ë¹„ë…¸']\n",
      "['ì•ˆë¼ìš”', 'í™ì§„ì˜']\n",
      "['G.B.T.B. (Strong Dragon Remix)', 'VERIVERY']\n",
      "['OFF', 'ìƒˆë²½ë‘ì‹œ']\n",
      "['I need you. Period.', 'Kim Jeong_uk(ê¹€ì •ìš±)']\n",
      "['ì¢‹ì•„ ì¢‹ì•„', 'ì •ë‹¤ê²½']\n",
      "['ê°•ì„ í–¥í•´ ê°„ë‹¤', 'ìŠ¤ë§ˆì¼ë¦¬ìŠ¤ë§ˆì¼ (SmileySmile)']\n",
      "['INTRCRSE (Feat. ë°”ë¼ë¦¬)', 'DOPA']\n",
      "['Fxxkin Insomnia', 'MÃ–A']\n",
      "['ì†Œë…„', 'ì‹ ì§€ë¯¼']\n",
      "['MOVIE (Feat. Rohann)', 'ì •ì§„ìš°']\n",
      "['í…… ë¹„ì—ˆë˜(ft. ì„œí•œ)', 'Xbf']\n",
      "[\"DIVIN' (Feat. z4vwm (ì¡ìŒ), JUICY KID)\", 'ì˜¨ë¦¬ì°¨ì¼ë“œ (ONLICHILD)']\n",
      "['ê·¸ëŒ€ ê·¸ë¦¬ìš´ ë‚ ', 'ì„¤ê°€ë ¹']\n",
      "['Love you Love you (feat.ë” ë¸Œë¦¿ì§€(The Bridge))', 'ë¸ŒëŸ°ì¹˜ ë ˆì‹œí”¼ (Brunch recipe)']\n",
      "['Labyrinth', 'ì •ì£¼ (Jungju)']\n",
      "['Be bop a lula', 'ì–¼ìŠ¤ (Earls), ì´ì² í˜¸']\n",
      "['Lazy Seoul (ë ˆì´ì§€ ì„œìš¸)', 'ì œì´ì¼ ']\n",
      "['ì˜¨ë„ì°¨', 'í™”ì (HWAJA)']\n",
      "['ë‚´ë²„ë ¤ë‘¬(NOYB)', 'BXK']\n",
      "['íƒœì–‘', 'ì´ì¤€í˜•']\n",
      "['Overdose (feat. Tommy Strate)', 'Claire Hau (í´ë ˆì–´ í•˜ìš°)']\n",
      "['My Love', 'ë‹¤ë¹„ì¹˜']\n",
      "['ìš°ë¦¬ ë©€ë¦¬ ë– ë‚ ê¹Œ (feat. ì •ê¸°ê³ )', 'ê³ ë‹¥']\n",
      "['minimal warm (ì·¨í–¥ì €ê²© ê·¸ë…€ X ì°¬ì—´ (CHANYEOL))', 'ì°¬ì—´ (CHANYEOL)']\n",
      "['My Universe (Prod. by Minit)', 'Holynn']\n",
      "['Traveler (feat. Zooy, Vibin)', 'TAETAE']\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import openpyxl\n",
    "\n",
    "wb = openpyxl.Workbook()\n",
    "sheet = wb.active\n",
    "sheet.append([\"ì œëª©\", \"ê°€ìˆ˜\"])\n",
    "\n",
    "\n",
    "naver_music_url = \"http://music.naver.com/listen/history/index.nhn?type=DOMESTIC&year=2017&month=12&week=1&page=\"\n",
    "\n",
    "def naver_music(url):    \n",
    "    html_music = requests.get(url).text\n",
    "    soup_music = BeautifulSoup(html_music, \"lxml\")\n",
    "\n",
    "    titles = soup_music.select('a._title span.ellipsis') \n",
    "    artists = soup_music.select('td._artist a')\n",
    "\n",
    "    music_titles = [title.get_text() for title in titles]\n",
    "    music_artists = [artist.get_text() for artist in artists]\n",
    "    return music_titles, music_artists\n",
    "\n",
    "\n",
    "for page in range(2):\n",
    "    naver_music_url_page = naver_music_url + str(page+1) # page URL\n",
    "    naver_music_titles, naver_music_artists = naver_music(naver_music_url_page)\n",
    "    \n",
    "    for k in range(len(naver_music_titles)):\n",
    "        sheet.append([music_titles[k].strip(), music_artists[k].strip()])\n",
    "        print([music_titles[k].strip(), music_artists[k].strip()])\n",
    "wb.save('C:/myPycode/data/fuckyou.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dynamite - ë°©íƒ„ì†Œë…„ë‹¨\n",
      "DON'T TOUCH ME - í™˜ë¶ˆì›ì •ëŒ€\n",
      "Lovesick Girls - BLACKPINK\n",
      "í˜ë“  ê±´ ì‚¬ë‘ì´ ì•„ë‹ˆë‹¤ - ì„ì°½ì •\n",
      "ì·¨ê¸°ë¥¼ ë¹Œë ¤ (ì·¨í–¥ì €ê²© ê·¸ë…€ X ì‚°ë“¤) - ì‚°ë“¤\n",
      "ì˜¤ë˜ëœ ë…¸ë˜ - ìŠ¤íƒ ë”© ì—ê·¸\n",
      "Savage Love (Laxed - Siren Beat) (BTS Remix) - Jawsh 685, Jason Derulo, ë°©íƒ„ì†Œë…„ë‹¨\n",
      "When We Disco (Duet with ì„ ë¯¸) - ë°•ì§„ì˜\n",
      "ë†“ì•„ì¤˜ (with íƒœì—°) - Crush\n",
      "ë‚´ ë§ˆìŒì´ ì›€ì°”í–ˆë˜ ìˆœê°„ (ì·¨í–¥ì €ê²© ê·¸ë…€ X ê·œí˜„) - ê·œí˜„ (KYUHYUN)\n",
      "ì ì´ ì˜¤ì§ˆ ì•Šë„¤ìš” - ì¥ë²”ì¤€\n",
      "ëˆˆëˆ„ë‚œë‚˜ (NUNU NANA) - ì œì‹œ (Jessi)\n",
      "ë§ˆë¦¬ì•„ (Maria) - í™”ì‚¬ (Hwa Sa)\n",
      "How You Like That - BLACKPINK\n",
      "ì—ì‡(Prod.&Feat. SUGA of BTS) - ì•„ì´ìœ \n",
      "í”ë“¤ë¦¬ëŠ” ê½ƒë“¤ ì†ì—ì„œ ë„¤ ìƒ´í‘¸í–¥ì´ ëŠê»´ì§„ê±°ì•¼ - ì¥ë²”ì¤€\n",
      "ë”©ê°€ë”©ê°€ (Dingga) - ë§ˆë§ˆë¬´ (Mamamoo)\n",
      "Dolphin - ì˜¤ë§ˆì´ê±¸ (OH MY GIRL)\n",
      "ì•„ë¡œí•˜ - ì¡°ì •ì„\n",
      "ì–´ë–»ê²Œ ì§€ë‚´ (Prod. By VAN.C) - ì˜¤ë°˜\n",
      "ë‹¤ì‹œ ì—¬ê¸° ë°”ë‹·ê°€ - ì‹¹ì“°ë¦¬ (ìœ ë‘ë˜ê³¤, ë¦°ë‹¤G, ë¹„ë£¡)\n",
      "ëŠ¦ì€ ë°¤ ë„ˆì˜ ì§‘ ì• ê³¨ëª©ê¸¸ì—ì„œ - ë…¸ì„\n",
      "í™€ë¡œ - ì´í•˜ì´\n",
      "I CANâ€™T STOP ME - TWICE (íŠ¸ì™€ì´ìŠ¤)\n",
      "Downtown Baby - ë¸”ë£¨ (BLOO)\n",
      "Dance Monkey - Tones And I\n",
      "Blueming - ì•„ì´ìœ \n",
      "ì–´ë–»ê²Œ ì´ë³„ê¹Œì§€ ì‚¬ë‘í•˜ê² ì–´, ë„ ì‚¬ë‘í•˜ëŠ” ê±°ì§€ - AKMU (ì•…ë™ë®¤ì§€ì…˜)\n",
      "METEOR - ì°½ëª¨ (CHANGMO)\n",
      "Memories - Maroon 5\n",
      "ê±°ì§“ë§ì´ë¼ë„ í•´ì„œ ë„ ë³´ê³ ì‹¶ì–´ - ë°±ì§€ì˜\n",
      "ëª¨ë“  ë‚ , ëª¨ë“  ìˆœê°„ (Every day, Every Moment) - í´í‚´\n",
      "ì‚¬ë‘ì€ ì§€ë‚ ìˆ˜ë¡ ë”ìš± ì„ ëª…í•˜ê²Œ ë‚¨ì•„ - ì „ìƒê·¼\n",
      "ì‘ì€ ê²ƒë“¤ì„ ìœ„í•œ ì‹œ (Boy With Luv) (Feat. Halsey) - ë°©íƒ„ì†Œë…„ë‹¨\n",
      "ì‚´ì§ ì„¤ë œì–´ (Nonstop) - ì˜¤ë§ˆì´ê±¸ (OH MY GIRL)\n",
      "ì„œë©´ì—­ì—ì„œ - ìˆœìˆœí¬\n",
      "Bad Boy - ì²­í•˜, Christopher\n",
      "ì˜¤ëŠ˜ë„ ë¹›ë‚˜ëŠ” ë„ˆì—ê²Œ (To You My Light) (Feat.ì´ë¼ì˜¨) - ë§ˆí¬íˆ½ (MAKTUB)\n",
      "ë„ˆë„ ì•„ëŠ” - í´í‚´\n",
      "2002 - Anne-Marie\n",
      "ìš°ë¦¬ ì™œ í—¤ì–´ì ¸ì•¼ í•´ - ì‹ ì˜ˆì˜\n",
      "ì‚¬ë‘í•˜ê²Œ ë  ì¤„ ì•Œì•˜ì–´ - ì „ë¯¸ë„\n",
      "ë§ˆìŒì„ ë“œë ¤ìš” - ì•„ì´ìœ \n",
      "Don't Start Now - Dua Lipa\n",
      "ë¤ë””ë¤ë”” (DUMDi DUMDi) - (ì—¬ì)ì•„ì´ë“¤\n",
      "ì²˜ìŒì²˜ëŸ¼ - ì— ì”¨ë”ë§¥ìŠ¤ (M.C the MAX)\n",
      "Ice Cream (with Selena Gomez) - BLACKPINK\n",
      "ì‚¬ë‘ ëª»í•´, ë‚¨ë“¤ ì‰½ê²Œ ë‹¤ í•˜ëŠ” ê±° - ë¨¼ë°ì´ í‚¤ì¦ˆ (Monday Kiz)\n",
      "ë‚˜ë‘ ê°™ì´ ê±¸ì„ë˜ (ë°”ë¥¸ì—°ì•  ê¸¸ì¡ì´ X ì ì¬) - ì ì¬\n",
      "Summer Hate (Feat. ë¹„) - ì§€ì½” (ZICO)\n",
      "Not Shy - ITZY (ìˆì§€)\n",
      "ë´„ë‚  - ë°©íƒ„ì†Œë…„ë‹¨\n",
      "ì•ˆë…• - í´í‚´\n",
      "Pretty Savage - BLACKPINK\n",
      "ì•„ë¬´ë…¸ë˜ - ì§€ì½” (ZICO)\n",
      "ë³´ë¼ë¹› ë°¤ (pporappippam) - ì„ ë¯¸\n",
      "12:45 (Stripped) - Etham\n",
      "ì‹œì‘ - ê°€í˜¸ (Gaho)\n",
      "ê°€ì„ íƒ€ë‚˜ ë´ - ë°”ì´ë¸Œ\n",
      "ON - ë°©íƒ„ì†Œë…„ë‹¨\n",
      "Maniac - Conan Gray\n",
      "ì´ì œ ë‚˜ë§Œ ë¯¿ì–´ìš” - ì„ì˜ì›…\n",
      "ì ì´ ë“¤ì–´ì•¼ (Feat. í—¤ì´ì¦ˆ) - ë¡œê¼¬\n",
      "Love poem - ì•„ì´ìœ \n",
      "ë„ˆë¥¼ ë§Œë‚˜ - í´í‚´\n",
      "ì¢‹ì€ ì‚¬ëŒ ìˆìœ¼ë©´ ì†Œê°œì‹œì¼œì¤˜ - ì¡°ì´ (JOY)\n",
      "Paris In The Rain - Lauv\n",
      "ë°¤ìƒˆ (ì·¨í–¥ì €ê²© ê·¸ë…€ X ì¹´ë”ê°€ë“ ) - ì¹´ë”ê°€ë“ \n",
      "Into the I-LAND - ì•„ì´ìœ \n",
      "ì¶•í•˜í•´ - ì˜¤ë°˜\n",
      "ì·¨í–ˆë‚˜ë´ - í™©ì¸ìš±\n",
      "ê·¸ë•Œ ê·¸ ì•„ì¸ - ê¹€í•„\n",
      "Psycho - Red Velvet (ë ˆë“œë²¨ë²³)\n",
      "ë³„ì„ ë‹´ì€ ì‹œ (Ode To The Stars) - ë§ˆí¬íˆ½ (MAKTUB), ì´ë¼ì˜¨\n",
      "í–‰ë³µí•´ - ì†¡í•˜ì˜ˆ\n",
      "ì‹œë“  ê½ƒì— ë¬¼ì„ ì£¼ë“¯ - HYNN (ë°•í˜œì›)\n",
      "ALIEN - ì´ìˆ˜í˜„\n",
      "bad guy - Billie Eilish\n",
      "ê·¸ ì—¬ë¦„ì„ í‹€ì–´ì¤˜ - ì‹¹ì“°ë¦¬ (ìœ ë‘ë˜ê³¤, ë¦°ë‹¤G, ë¹„ë£¡)\n",
      "Painkiller - Ruel\n",
      "ë‚˜ë¹„ì™€ ê³ ì–‘ì´ (feat.ë°±í˜„ (BAEKHYUN)) - ë³¼ë¹¨ê°„ì‚¬ì¶˜ê¸°\n",
      "í•˜ë£¨ë„ ê·¸ëŒ€ë¥¼ ì‚¬ë‘í•˜ì§€ ì•Šì€ ì ì´ ì—†ì—ˆë‹¤ - ì„ì°½ì •\n",
      "í–‰ë³µí•˜ë‹ˆ - ì¼€ì´ì‹œ (Kassy)\n",
      "ì†Œí™•í–‰ - ì„ì°½ì •\n",
      "Bet You Wanna (Feat. Cardi B) - BLACKPINK\n",
      "Stuck with U - Ariana Grande, Justin Bieber\n",
      "ë°˜ë§Œ - ì§„ë¯¼í˜¸\n",
      "ì‚¬ë‘í•˜ê³  ì‹¶ì§€ ì•Šì•„ (ë°”ë¥¸ì—°ì•  ê¸¸ì¡ì´ X XIA (ì¤€ìˆ˜)) - ê¹€ì¤€ìˆ˜\n",
      "ì²« ì¤„ - ì‹ ìš©ì¬ (2F)\n",
      "í™”ë ¤í•˜ì§€ ì•Šì€ ê³ ë°± - ê·œí˜„ (KYUHYUN)\n",
      "ì‚¬ë‘ì´ë€ ë©œë¡œëŠ” ì—†ì–´ - ì „ìƒê·¼\n",
      "Tip Toe (with ì´í•˜ì´) - Crush\n",
      "ë°¤í•˜ëŠ˜ì˜ ì € ë³„ì²˜ëŸ¼ - í—¤ì´ì¦ˆ (Heize), í€ì¹˜ (Punch)\n",
      "ì‹ ë‚œë‹¤ (Feat. ë§ˆë§ˆë¬´) - ë¹„ë£¡\n",
      "ë„ˆë¥¼ ì‚¬ë‘í•˜ê³  ìˆì–´ - ë°±í˜„ (BAEKHYUN)\n",
      "HIP - ë§ˆë§ˆë¬´ (Mamamoo)\n",
      "MORE & MORE - TWICE (íŠ¸ì™€ì´ìŠ¤)\n",
      "To Die For - Sam Smith\n",
      "00:00 (Zero Oâ€™Clock) - ë°©íƒ„ì†Œë…„ë‹¨\n",
      "ë„ˆì˜ ë°¤ì€ ì–´ë•Œ (ì·¨í–¥ì €ê²© ê·¸ë…€ X ì •ì€ì§€) - ì •ì€ì§€\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import openpyxl\n",
    "\n",
    "wb = openpyxl.Workbook()\n",
    "sheet = wb.active\n",
    "sheet.append(['ìˆœìœ„', \"ì œëª©\", \"ê°€ìˆ˜\"])\n",
    "\n",
    "\n",
    "headers = {'User-Agent':'Mozilla/5.0 (Windows NT 6.3; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/63.0.3239.132 Safari/537.36'}\n",
    "\n",
    "url = 'https://www.melon.com/chart/week/index.htm'\n",
    "\n",
    "html_music = requests.get(url, headers = headers).text\n",
    "soup_music = BeautifulSoup(html_music, \"lxml\")\n",
    "\n",
    "titles = soup_music.select('td div.ellipsis.rank01') \n",
    "artists = soup_music.select('td div.ellipsis.rank02 span') \n",
    "\n",
    "music_titles = [title.get_text() for title in titles]\n",
    "music_artists = [artist.get_text() for artist in artists]\n",
    "\n",
    "for k in range(len(music_titles)):\n",
    "    sheet.append([k+1, music_titles[k].strip(), music_artists[k].strip()])\n",
    "    print(music_titles[k].strip(), '-', music_artists[k].strip())\n",
    "wb.save('C:/myPycode/data/fuckyoumelon.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'selenium'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-5caa8467b724>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mselenium\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mwebdriver\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mbs4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mdriver\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwebdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mChrome\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'c:/chromedriver'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimplicitly_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'selenium'"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "driver = webdriver.Chrome('c:/chromedriver')\n",
    "driver.implicitly_wait(3)\n",
    "driver.get('http://music.naver.com/listen/history/index.nhn?type=DOMESTIC&year=2017&month=12&week=1&page=1')\n",
    "\n",
    "driver.find_element_by_xpath('//*[@id=\"content\"]/div[3]/div[2]/div[1]/table/tbody/tr[6]/td[5]/a').click()\n",
    "html = driver.page_source\n",
    "\n",
    "soup = BeautifulSoup(html, 'lxml')\n",
    "result = soup.select('div.scrollbar-content')\n",
    "\n",
    "artists = result[3].get_text()\n",
    "artists_first = artists[0:3]\n",
    "artists_second = artists[3:]\n",
    "\n",
    "print(artists_first+\", \"+ artists_second)\n",
    "\n",
    "rank5 = artists_first+\", \"+ artists_second\n",
    "\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ì›¹í˜ì´ì§€ì—ì„œ ì´ë¯¸ì§€ ê°€ì ¸ì˜¤ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests  \n",
    "\n",
    "url = 'https://www.python.org/static/img/python-logo.png'\n",
    "html_image = requests.get(url)\n",
    "html_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'python-logo.png'"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "image_file_name = os.path.basename(url)\n",
    "image_file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = 'C:/myPyCode/download' \n",
    "\n",
    "if not os.path.exists(folder):\n",
    "    os.makedirs(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:/myPyCode/download\\\\python-logo.png'"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_path = os.path.join(folder, image_file_name)\n",
    "image_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "imageFile = open(image_path, 'wb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì´ë¯¸ì§€ ë°ì´í„°ë¥¼ 1000000 ë°”ì´íŠ¸ì”© ë‚˜ëˆ ì„œ ë‚´ë ¤ë°›ê³  íŒŒì¼ì— ìˆœì°¨ì ìœ¼ë¡œ ì €ì¥\n",
    "chunk_size = 1000000\n",
    "for chunk in html_image.iter_content(chunk_size):\n",
    "    imageFile.write(chunk)\n",
    "imageFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['python-logo.png']"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests  \n",
    "import os\n",
    "\n",
    "url = 'https://www.python.org/static/img/python-logo.png'\n",
    "html_image = requests.get(url)\n",
    "image_file_name = os.path.basename(url)\n",
    "\n",
    "folder = 'C:/myPyCode/download' \n",
    "\n",
    "if not os.path.exists(folder):\n",
    "    os.makedirs(folder)\n",
    "\n",
    "image_path = os.path.join(folder, image_file_name)\n",
    "\n",
    "imageFile = open(image_path, 'wb')\n",
    "# ì´ë¯¸ì§€ ë°ì´í„°ë¥¼ 1000000 ë°”ì´íŠ¸ì”© ë‚˜ëˆ ì„œ ì €ì¥\n",
    "chunk_size = 1000000\n",
    "for chunk in html_image.iter_content(chunk_size):\n",
    "    imageFile.write(chunk)\n",
    "imageFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests  \n",
    "import os\n",
    "\n",
    "url = 'https://imgnews.pstatic.net/image/011/2020/10/31/0003818880_001_20201031180544196.jpg'\n",
    "html_image = requests.get(url)\n",
    "image_file_name = os.path.basename(url)\n",
    "\n",
    "folder = 'C:/myPyCode/download' \n",
    "\n",
    "if not os.path.exists(folder):\n",
    "    os.makedirs(folder)\n",
    "\n",
    "image_path = os.path.join(folder, image_file_name)\n",
    "\n",
    "imageFile = open(image_path, 'wb')\n",
    "# ì´ë¯¸ì§€ ë°ì´í„°ë¥¼ 1000000 ë°”ì´íŠ¸ì”© ë‚˜ëˆ ì„œ ì €ì¥\n",
    "chunk_size = 1000000\n",
    "for chunk in html_image.iter_content(chunk_size):\n",
    "    imageFile.write(chunk)\n",
    "imageFile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ì—¬ëŸ¬ ì´ë¯¸ì§€ ë‚´ë ¤ë°›ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<img alt=\"Reshot navbar logo\" class=\"black\" src=\"https://assets-static.reshot-cdn.com/brand/reshot-logo.png\"/>,\n",
       " <img alt=\"Free authentic animals photo on Reshot\" src=\"https://res.cloudinary.com/twenty20/private_images/t_standard-fit/v1521838685/photosp/bae96789-a5ab-4471-b54f-9686ace09e33/bae96789-a5ab-4471-b54f-9686ace09e33.jpg\"/>,\n",
       " <img alt=\"Back off!\" src=\"https://res.cloudinary.com/twenty20/private_images/t_standard-fit/v1597098233/photosp/a44357c5-b1c3-41ef-9a65-7a4937b06a44/a44357c5-b1c3-41ef-9a65-7a4937b06a44.jpg\"/>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = 'https://www.reshot.com/search/animals'\n",
    "\n",
    "html_reshot_image = requests.get(url).text\n",
    "\n",
    "soup_reshot_image = BeautifulSoup(html_reshot_image, 'lxml')\n",
    "\n",
    "\n",
    "reshot_image_elements = soup_reshot_image.select('a img')\n",
    "\n",
    "reshot_image_elements[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://res.cloudinary.com/twenty20/private_images/t_standard-fit/v1521838685/photosp/bae96789-a5ab-4471-b54f-9686ace09e33/bae96789-a5ab-4471-b54f-9686ace09e33.jpg'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reshot_image_url = reshot_image_elements[1].get('src')\n",
    "reshot_image_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_image = requests.get(reshot_image_url)\n",
    "\n",
    "folder = \"C:/myPyCode/download\"\n",
    "    \n",
    "# os.path.basename(URL)ëŠ” ì›¹ì‚¬ì´íŠ¸ë‚˜ í´ë”ê°€ í¬í•¨ëœ íŒŒì¼ëª…ì—ì„œ íŒŒì¼ëª…ë§Œ ë¶„ë¦¬í•˜ëŠ” ë°©ë²•    \n",
    "imageFile = open(os.path.join(folder, os.path.basename(reshot_image_url)), 'wb')\n",
    "\n",
    "# ì´ë¯¸ì§€ ë°ì´í„°ë¥¼ 1000000 ë°”ì´íŠ¸ì”© ë‚˜ëˆ ì„œ ì €ì¥í•˜ëŠ” ë°©ë²•\n",
    "chunk_size = 1000000 \n",
    "for chunk in html_image.iter_content(chunk_size):\n",
    "    imageFile.write(chunk)\n",
    "imageFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "MissingSchema",
     "evalue": "Invalid URL '//search1.daumcdn.net/search/statics/common/pi/logo/daumlogo_170324.png': No schema supplied. Perhaps you meant http:////search1.daumcdn.net/search/statics/common/pi/logo/daumlogo_170324.png?",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMissingSchema\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-26768a6018fd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_of_download_image\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m     \u001b[0mdownload_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigure_folder\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpixabay_image_urls\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"================================\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"ì„ íƒí•œ ëª¨ë“  ì´ë¯¸ì§€ ë‚´ë ¤ë°›ê¸° ì™„ë£Œ!\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-21-26768a6018fd>\u001b[0m in \u001b[0;36mdownload_image\u001b[1;34m(img_folder, img_url)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mdownload_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_folder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg_url\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_url\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m         \u001b[0mhtml_image\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_url\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m         \u001b[1;31m# os.path.basename(URL)ëŠ” ì›¹ì‚¬ì´íŠ¸ë‚˜ í´ë”ê°€ í¬í•¨ëœ íŒŒì¼ëª…ì—ì„œ íŒŒì¼ëª…ë§Œ ë¶„ë¦¬\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[0mimageFile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_folder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_url\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\requests\\api.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(url, params, **kwargs)\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'allow_redirects'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 76\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'get'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     77\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\requests\\api.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[1;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\requests\\sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    514\u001b[0m             \u001b[0mhooks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    515\u001b[0m         )\n\u001b[1;32m--> 516\u001b[1;33m         \u001b[0mprep\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprepare_request\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    517\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    518\u001b[0m         \u001b[0mproxies\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mproxies\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\requests\\sessions.py\u001b[0m in \u001b[0;36mprepare_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    447\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    448\u001b[0m         \u001b[0mp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPreparedRequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 449\u001b[1;33m         p.prepare(\n\u001b[0m\u001b[0;32m    450\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    451\u001b[0m             \u001b[0murl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\requests\\models.py\u001b[0m in \u001b[0;36mprepare\u001b[1;34m(self, method, url, headers, files, data, params, auth, cookies, hooks, json)\u001b[0m\n\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprepare_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 314\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprepare_url\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    315\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprepare_headers\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    316\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprepare_cookies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcookies\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\requests\\models.py\u001b[0m in \u001b[0;36mprepare_url\u001b[1;34m(self, url, params)\u001b[0m\n\u001b[0;32m    386\u001b[0m             \u001b[0merror\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0merror\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mto_native_string\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'utf8'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    387\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 388\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mMissingSchema\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    389\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    390\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhost\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMissingSchema\u001b[0m: Invalid URL '//search1.daumcdn.net/search/statics/common/pi/logo/daumlogo_170324.png': No schema supplied. Perhaps you meant http:////search1.daumcdn.net/search/statics/common/pi/logo/daumlogo_170324.png?"
     ]
    }
   ],
   "source": [
    "import requests  \n",
    "from bs4 import BeautifulSoup \n",
    "import os\n",
    "\n",
    "# URL(ì£¼ì†Œ)ì—ì„œ ì´ë¯¸ì§€ ì£¼ì†Œ ì¶”ì¶œ\n",
    "def get_image_url(url): \n",
    "    html_image_url = requests.get(url).text\n",
    "    soup_image_url = BeautifulSoup(html_image_url, \"lxml\")  \n",
    "    image_elements = soup_image_url.select('a img') \n",
    "    if(image_elements != None):\n",
    "        image_urls = []\n",
    "        for image_element in image_elements:\n",
    "            image_urls.append(image_element.get('src'))\n",
    "        return image_urls        \n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "# í´ë”ë¥¼ ì§€ì •í•´ ì´ë¯¸ì§€ ì£¼ì†Œì—ì„œ ì´ë¯¸ì§€ ë‚´ë ¤ë°›ê¸°\n",
    "def download_image(img_folder, img_url):\n",
    "    if(img_url != None):  \n",
    "        html_image = requests.get(img_url)\n",
    "        # os.path.basename(URL)ëŠ” ì›¹ì‚¬ì´íŠ¸ë‚˜ í´ë”ê°€ í¬í•¨ëœ íŒŒì¼ëª…ì—ì„œ íŒŒì¼ëª…ë§Œ ë¶„ë¦¬    \n",
    "        imageFile = open(os.path.join(img_folder, os.path.basename(img_url)), 'wb')\n",
    "\n",
    "        chunk_size = 1000000 # ì´ë¯¸ì§€ ë°ì´í„°ë¥¼ 1000000 ë°”ì´íŠ¸ì”© ë‚˜ëˆ ì„œ ì €ì¥\n",
    "        for chunk in html_image.iter_content(chunk_size):\n",
    "            imageFile.write(chunk)\n",
    "            imageFile.close()\n",
    "        print(\"ì´ë¯¸ì§€ íŒŒì¼ëª…: '{0}'. ë‚´ë ¤ë°›ê¸° ì™„ë£Œ!\".format(os.path.basename(img_url))) \n",
    "    else:       \n",
    "        print(\"ë‚´ë ¤ë°›ì„ ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        \n",
    "# ì›¹ ì‚¬ì´íŠ¸ì˜ ì£¼ì†Œ ì§€ì •   \n",
    "pixabay_url = 'https://search.daum.net/search?w=img&nil_search=btn&DA=NTB&enc=utf8&q=%ED%8A%B8%EB%9F%BC%ED%94%84'\n",
    "# pixabay_url= 'https://pixabay.com/ko/photos/?order=popular&cat=animals&pagi=2'\n",
    "\n",
    "figure_folder = \"C:/myPyCode/download/trump\" # ì´ë¯¸ì§€ë¥¼ ë‚´ë ¤ë°›ì„ í´ë” ì§€ì •  \n",
    "if not os.path.exists(figure_folder):\n",
    "    os.makedirs(figure_folder)\n",
    "    \n",
    "pixabay_image_urls = get_image_url(pixabay_url) # ì´ë¯¸ì§€ íŒŒì¼ì˜ ì£¼ì†Œ ê°€ì ¸ì˜¤ê¸°\n",
    "\n",
    "num_of_download_image = 7 # ë‚´ë ¤ë°›ì„ ì´ë¯¸ì§€ ê°œìˆ˜ ì§€ì •\n",
    "# num_of_download_image = len(pixabay_image_urls)\n",
    "\n",
    "for k in range(num_of_download_image+1):\n",
    "    download_image(figure_folder,pixabay_image_urls[k])\n",
    "print(\"================================\")\n",
    "print(\"ì„ íƒí•œ ëª¨ë“  ì´ë¯¸ì§€ ë‚´ë ¤ë°›ê¸° ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kfc download complete\n",
      "done!!\n"
     ]
    }
   ],
   "source": [
    "## ì„ ì–¸\n",
    "import os\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from urllib.parse import quote_plus\n",
    "\n",
    "baseUrl = 'https://search.naver.com/search.naver?where=image&sm=tab_jum&query='\n",
    "\n",
    "\n",
    "save_root = 'C:\\myPycode\\download'\n",
    "if not os.path.exists(save_root):os.makedirs(save_root)\n",
    "\n",
    "def get_images(query='apple', limit=20):\n",
    "    save_path = os.path.join(save_root, query)\n",
    "    if not os.path.exists(save_path):\n",
    "        os.makedirs(save_path)\n",
    "    \n",
    "    # í•œê¸€ ê²€ìƒ‰ ìë™ ë³€í™˜\n",
    "    url = baseUrl + quote_plus(query)\n",
    "    html = urlopen(url)\n",
    "    soup = bs(html, \"html.parser\")\n",
    "    img = soup.find_all(class_='_img', limit=limit)\n",
    "\n",
    "    n = 1\n",
    "    for i in img:\n",
    "        imgUrl = i['data-source']\n",
    "        with urlopen(imgUrl) as f:\n",
    "            with open(os.path.join(save_path, str(n)+'.jpg'),'wb') as h: # w - write b - binary\n",
    "                img = f.read()\n",
    "                h.write(img)\n",
    "        n += 1\n",
    "    print('%s download complete' % (query))\n",
    "    \n",
    "queries =  ['kfc']\n",
    "\n",
    "num_limit = 1100\n",
    "    \n",
    "for query in queries:\n",
    "    get_images(query=query, limit=num_limit)\n",
    "    \n",
    "print('done!!');beep = lambda x: os.system(\"echo -n '\\a';sleep 0.3;\" * x);beep(3);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "url = 'https://www.python.org/static/img/python-logo.png'\n",
    "html_image = requests.get(url)\n",
    "html_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'python-logo.png'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "image_file_name = os.path.basename(url)\n",
    "image_file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:/myPyCode/download\\\\python-logo.png'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_path = os.path.join(folder, image_file_name)\n",
    "image_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "imageFile = open(image_path, 'wb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "chujnk_size = 1000000\n",
    "for chunk in html_image.iter_content(chunk_size):\n",
    "    imageFile.write(chunk)\n",
    "imageFile.close()"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
